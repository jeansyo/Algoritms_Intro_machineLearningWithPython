{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BETO examples",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jean-Rd/Algoritms_Intro_machineLearningWithPython/blob/master/my_beto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhAqZLs3lwhW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce03b5e6-55b5-4d20-f5bb-4d1467cb219c"
      },
      "source": [
        "# Fist install the library and download the models from github\n",
        "\n",
        "!pip install transformers\n",
        "!wget https://users.dcc.uchile.cl/~jperez/beto/cased_2M/pytorch_weights.tar.gz \n",
        "!wget https://users.dcc.uchile.cl/~jperez/beto/cased_2M/vocab.txt \n",
        "!wget https://users.dcc.uchile.cl/~jperez/beto/cased_2M/config.json \n",
        "!tar -xzvf pytorch_weights.tar.gz\n",
        "!mv config.json pytorch/.\n",
        "!mv vocab.txt pytorch/."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 33.2MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 29.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Installing collected packages: sacremoses, tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n",
            "--2021-06-15 22:57:12--  https://users.dcc.uchile.cl/~jperez/beto/cased_2M/pytorch_weights.tar.gz\n",
            "Resolving users.dcc.uchile.cl (users.dcc.uchile.cl)... 192.80.24.4, 200.9.99.211\n",
            "Connecting to users.dcc.uchile.cl (users.dcc.uchile.cl)|192.80.24.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 409871727 (391M) [application/x-gzip]\n",
            "Saving to: ‘pytorch_weights.tar.gz’\n",
            "\n",
            "pytorch_weights.tar 100%[===================>] 390.88M  6.19MB/s    in 53s     \n",
            "\n",
            "2021-06-15 22:58:05 (7.44 MB/s) - ‘pytorch_weights.tar.gz’ saved [409871727/409871727]\n",
            "\n",
            "--2021-06-15 22:58:05--  https://users.dcc.uchile.cl/~jperez/beto/cased_2M/vocab.txt\n",
            "Resolving users.dcc.uchile.cl (users.dcc.uchile.cl)... 200.9.99.211, 192.80.24.4\n",
            "Connecting to users.dcc.uchile.cl (users.dcc.uchile.cl)|200.9.99.211|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 242120 (236K) [text/plain]\n",
            "Saving to: ‘vocab.txt’\n",
            "\n",
            "vocab.txt           100%[===================>] 236.45K   406KB/s    in 0.6s    \n",
            "\n",
            "2021-06-15 22:58:07 (406 KB/s) - ‘vocab.txt’ saved [242120/242120]\n",
            "\n",
            "--2021-06-15 22:58:07--  https://users.dcc.uchile.cl/~jperez/beto/cased_2M/config.json\n",
            "Resolving users.dcc.uchile.cl (users.dcc.uchile.cl)... 200.9.99.211, 192.80.24.4\n",
            "Connecting to users.dcc.uchile.cl (users.dcc.uchile.cl)|200.9.99.211|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 313 [application/json]\n",
            "Saving to: ‘config.json’\n",
            "\n",
            "config.json         100%[===================>]     313  --.-KB/s    in 0s      \n",
            "\n",
            "2021-06-15 22:58:08 (47.9 MB/s) - ‘config.json’ saved [313/313]\n",
            "\n",
            "pytorch/\n",
            "pytorch/pytorch_model.bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_1ucCCUnXqa"
      },
      "source": [
        "# import the necessary\n",
        "\n",
        "import torch\n",
        "from transformers import BertForMaskedLM, BertTokenizer"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCpOxoXkoGFC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b273f98-a630-42d3-ba26-ee768c6dcc4d"
      },
      "source": [
        "# create the tokenizer and the model\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"pytorch/\", do_lower_case=False)\n",
        "model = BertForMaskedLM.from_pretrained(\"pytorch/\")\n",
        "e = model.eval()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at pytorch/ were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KXo6-ahoJoM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ea3867f-b055-4249-8314-cffff442987d"
      },
      "source": [
        "# Now test it\n",
        "\n",
        "text = \"[CLS] Bolivia perdio su [MASK], en el [MASK]. [SEP]\"\n",
        "masked_indxs = (5,9)\n",
        "\n",
        "tokens = tokenizer.tokenize(text)\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokens)\n",
        "tokens_tensor = torch.tensor([indexed_tokens])\n",
        "\n",
        "predictions = model(tokens_tensor)[0]\n",
        "\n",
        "for i,midx in enumerate(masked_indxs):\n",
        "    idxs = torch.argsort(predictions[0,midx], descending=True)\n",
        "    predicted_token = tokenizer.convert_ids_to_tokens(idxs[:5])\n",
        "    print('MASK',i,':',predicted_token)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MASK 0 : ['independencia', 'soberanía', 'territorio', 'autonomía', 'nombre']\n",
            "MASK 1 : ['[UNK]', '2008', '2010', '2014', '2009']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb9CZLSgQphw",
        "outputId": "e3c672a3-4061-4ed5-a97e-4cc2e5475dbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "type(list(model.children())[-1])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transformers.models.bert.modeling_bert.BertOnlyMLMHead"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JToqeBz8Dwun",
        "outputId": "ef27fb80-795c-475c-ec8f-317937d8b81a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(list(model.children())[-1])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BertOnlyMLMHead(\n",
            "  (predictions): BertLMPredictionHead(\n",
            "    (transform): BertPredictionHeadTransform(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "    )\n",
            "    (decoder): Linear(in_features=768, out_features=31002, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04KlUXerC2LA"
      },
      "source": [
        "import transformers\n",
        "import pytorch"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wpn-_AsGC2Qf"
      },
      "source": [
        "transformers.models.bert.modeling_bert.BertOnlyMLMHead"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EQn3xW0G8IF"
      },
      "source": [
        "def gelu(x):\n",
        "    \"\"\" Original Implementation of the gelu activation function in Google Bert repo when initially created.\n",
        "        For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\n",
        "        0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
        "        Also see https://arxiv.org/abs/1606.08415\n",
        "    \"\"\"\n",
        "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n",
        "\n",
        "\n",
        "def gelu_new(x):\n",
        "    \"\"\" Implementation of the gelu activation function currently in Google Bert repo (identical to OpenAI GPT).\n",
        "        Also see https://arxiv.org/abs/1606.08415\n",
        "    \"\"\"\n",
        "    return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
        "\n",
        "\n",
        "def swish(x):\n",
        "    return x * torch.sigmoid(x)\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bg1rRc9_GsNN"
      },
      "source": [
        "ACT2FN = {\"gelu\": gelu, \"relu\": torch.nn.functional.relu, \"swish\": swish, \"gelu_new\": gelu_new}"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IT0SMRiqC2Tg"
      },
      "source": [
        "class BertPredictionHeadTransform(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, config):\n",
        "\n",
        "    super().__init__()\n",
        "    self.dense = torch.nn.Linear(config.hidden_size, config.hidden_size)\n",
        "    if isinstance(config.hidden_act, str):\n",
        "      self.transform_act_fn = ACT2FN[config.hidden_act]\n",
        "    else:\n",
        "      self.transform_act_fn = ACT2FN(config.hidden_act)\n",
        "    self.layernorm = torch.nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
        "\n",
        "\n",
        "  def forward(self, hidden_states):\n",
        "\n",
        "    hidden_states = self.dense(hidden_states)\n",
        "    hidden_states = self.transform_act_fn(hidden_states)\n",
        "    hidden_states = self.dense(hidden_states)\n",
        "    hidden_states = self.transform_act_fn(hidden_states)\n",
        "    hidden_states = self.layernorm(hidden_states)\n",
        "\n",
        "    return hidden_states\n",
        "\n",
        "\n",
        "class BertLMPredictionHead(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.transform = BertPredictionHeadTransform(config)\n",
        "    self.decoder = torch.nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n",
        "    self.bias = torch.nn.Parameter(torch.zeros(config.vocab_size))\n",
        "\n",
        "    self.decoder.bias = self.bias\n",
        "\n",
        "  def forward(self, hidden_states):\n",
        "\n",
        "    hidden_states = self.transform(hidden_states)\n",
        "    hidden_states = self.decoder(hidden_states)\n",
        "\n",
        "    return hidden_states\n",
        "\n",
        "\n",
        "class BertOnlyMLMHead(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, config):\n",
        "\n",
        "    super().__init__()\n",
        "    self.prediction = BertLMPredictionHead(config)\n",
        "\n",
        "  def forward(self, sequence_output):\n",
        "\n",
        "    prediction_scores = self.prediction(sequence_output)\n",
        "    return prediction_scores"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Zv7kkriR1Lm"
      },
      "source": [
        "class Config:\n",
        "\n",
        "  def __init__(self, **kwargs):\n",
        "\n",
        "    self.hidden_size = kwargs['hidden_size']\n",
        "    self.vocab_size = kwargs['vocab_size']\n",
        "    self.layer_norm_eps = kwargs['layer_norm_eps']\n",
        "    self.hidden_act = kwargs['hidden_act']"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mv0t9oVRC2We"
      },
      "source": [
        "config = Config(hidden_size=768, vocab_size=31002, layer_norm_eps=1e-12, hidden_act='gelu_new')"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8173AHuTNNH",
        "outputId": "d220847d-ab52-47de-e360-4235d6ebc818",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "BertOnlyMLMHead(config)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertOnlyMLMHead(\n",
              "  (prediction): BertLMPredictionHead(\n",
              "    (transform): BertPredictionHeadTransform(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): Linear(in_features=768, out_features=31002, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaLHauchXYed"
      },
      "source": [
        ""
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nama7sRSTNQ3"
      },
      "source": [
        "class Model(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, out_features=31002, freeze=False):\n",
        "\n",
        "    super().__init__()\n",
        "    model_beto = model\n",
        "\n",
        "    self.model_beto = torch.nn.Sequential(*list(model_beto.children())[:-1])\n",
        "\n",
        "    if freeze:\n",
        "      for param in self.model_beto.parameters():\n",
        "        param.requires_grad = False\n",
        "      \n",
        "    self.fc_output = BertOnlyMLMHead(config)\n",
        "\n",
        "  def forward(self, status_hidden):\n",
        "\n",
        "    status_hidden = self.fc_output(status_hidden)\n",
        "    return status_hidden\n"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bdns7qSMC2ZZ"
      },
      "source": [
        "my_beto = Model(freeze=True)"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XJU5_z5C2ce"
      },
      "source": [
        ""
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pIh5QJeZE7F"
      },
      "source": [
        ""
      ],
      "execution_count": 136,
      "outputs": []
    }
  ]
}